{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group 8 Assignment Phase 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intitializing Scala interpreter ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Spark Web UI available at http://22ef46be2451:4041\n",
       "SparkContext available as 'sc' (version = 2.4.5, master = local[*], app id = local-1590564308401)\n",
       "SparkSession available as 'spark'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql.SparkSession\n",
       "import org.apache.spark.sql.functions._\n",
       "import org.apache.spark.sql.types._\n",
       "import org.apache.spark.sql._\n",
       "import org.apache.log4j._\n",
       "spark: org.apache.spark.sql.SparkSession = org.apache.spark.sql.SparkSession@d477063\n"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//Start a simple Spark Session\n",
    "import org.apache.spark.sql.SparkSession\n",
    "import org.apache.spark.sql.functions._\n",
    "import org.apache.spark.sql.types._\n",
    "import org.apache.spark.sql._\n",
    "\n",
    "//Optional: Use the following code below to set the Error reporting\n",
    "import org.apache.log4j._\n",
    "Logger.getLogger(\"org\").setLevel(Level.ERROR)\n",
    "\n",
    "\n",
    "//For Cleaning\n",
    "//import scala.util.matching.Regex\n",
    "\n",
    "val spark = SparkSession.builder().getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Monthly Fuel Price and Flight Delay Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "flightDelaySchema: org.apache.spark.sql.types.StructType = StructType(StructField(Route,StringType,false), StructField(Departing_Port,StringType,false), StructField(Arriving_Port,StringType,false), StructField(Airline,StringType,false), StructField(Month,StringType,false), StructField(Sectors_Scheduled,IntegerType,false), StructField(Sectors_Flown,IntegerType,false), StructField(Cancellations,IntegerType,false), StructField(Departures_On_Time,IntegerType,false), StructField(Arrivals_On_Time,IntegerType,false), StructField(Departures_Delayed,IntegerType,false), StructField(Arrivals_Delayed,IntegerType,false), StructField(Year,IntegerType,false), StructField(Month_Num,IntegerType,false))\n",
       "fuelDF: org.apache.spark.sql.DataFrame = [Month: string, Price: double ... 1 more field]\n",
       "readflightDel..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val flightDelaySchema = StructType(List(\n",
    "    StructField(\"Route\", StringType, nullable = false),\n",
    "    StructField(\"Departing_Port\", StringType, nullable = false),\n",
    "    StructField(\"Arriving_Port\", StringType, nullable = false),\n",
    "    StructField(\"Airline\", StringType, nullable = false),\n",
    "    StructField(\"Month\", StringType, nullable = false),\n",
    "    StructField(\"Sectors_Scheduled\", IntegerType, nullable = false),\n",
    "    StructField(\"Sectors_Flown\", IntegerType, nullable = false),\n",
    "    StructField(\"Cancellations\", IntegerType, nullable = false),\n",
    "    StructField(\"Departures_On_Time\", IntegerType, nullable = false),\n",
    "    StructField(\"Arrivals_On_Time\", IntegerType, nullable = false),\n",
    "    StructField(\"Departures_Delayed\", IntegerType, nullable = false),\n",
    "    StructField(\"Arrivals_Delayed\", IntegerType, nullable = false),\n",
    "    StructField(\"Year\", IntegerType, nullable = false),\n",
    "    StructField(\"Month_Num\", IntegerType, nullable = false)\n",
    "))\n",
    "\n",
    "\n",
    "val fuelDF = spark.read\n",
    "    .option(\"delimiter\",\",\")\n",
    "    .option(\"header\", \"true\")\n",
    "    .option(\"inferSchema\", \"true\")\n",
    "    .csv(\"jetfuel.csv\")\n",
    "\n",
    "val readflightDelayDF = spark\n",
    "    .read\n",
    "    .schema(flightDelaySchema)\n",
    "    .option(\"delimiter\",\",\")\n",
    "    .option(\"header\", \"true\")\n",
    "    .csv(\"otp_time_series_web.csv\")\n",
    "    .where(($\"Airline\" =!= \"All Airlines\") )   //Remove All Ports from monthly totals\n",
    "    .where($\"Route\" =!= \"All Ports-All Ports\") //Remove All Airlines from monthly totals\n",
    "    .select(\"Month\",\n",
    "          \"Departing_Port\", \n",
    "          \"Arriving_Port\", \n",
    "          \"Airline\", \n",
    "          \"Sectors_Flown\",\n",
    "          \"Departures_Delayed\",\n",
    "          \"Year\", \n",
    "          \"Month_Num\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------+-------------+-------+-------------+------------------+----+---------+\n",
      "| Month|Departing_Port|Arriving_Port|Airline|Sectors_Flown|Departures_Delayed|Year|Month_Num|\n",
      "+------+--------------+-------------+-------+-------------+------------------+----+---------+\n",
      "|Jan-04|      Adelaide|     Brisbane| Qantas|           93|                12|2004|        1|\n",
      "|Jan-04|      Adelaide|     Canberra| Qantas|           48|                 3|2004|        1|\n",
      "|Jan-04|      Adelaide|   Gold Coast| Qantas|            9|                 1|2004|        1|\n",
      "|Jan-04|      Adelaide|    Melbourne| Qantas|          350|                33|2004|        1|\n",
      "|Jan-04|      Adelaide|        Perth| Qantas|          130|                 9|2004|        1|\n",
      "+------+--------------+-------------+-------+-------------+------------------+----+---------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+--------------+\n",
      "|Departing_Port|\n",
      "+--------------+\n",
      "|  Port Lincoln|\n",
      "|        Cairns|\n",
      "|      Armidale|\n",
      "|      Canberra|\n",
      "|Sunshine Coast|\n",
      "|     Mount Isa|\n",
      "|      Adelaide|\n",
      "|      Tamworth|\n",
      "|    Proserpine|\n",
      "|Port Macquarie|\n",
      "|       Ballina|\n",
      "|       Mildura|\n",
      "|     Bundaberg|\n",
      "|      Brisbane|\n",
      "|        Sydney|\n",
      "|     Gladstone|\n",
      "|         Perth|\n",
      "|        Burnie|\n",
      "|       Emerald|\n",
      "|    Ayers Rock|\n",
      "+--------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+--------------+\n",
      "| Arriving_Port|\n",
      "+--------------+\n",
      "|  Port Lincoln|\n",
      "|        Cairns|\n",
      "|      Armidale|\n",
      "|      Canberra|\n",
      "|Sunshine Coast|\n",
      "|     Mount Isa|\n",
      "|      Adelaide|\n",
      "|      Tamworth|\n",
      "|    Proserpine|\n",
      "|Port Macquarie|\n",
      "|       Ballina|\n",
      "|       Mildura|\n",
      "|     Bundaberg|\n",
      "|      Brisbane|\n",
      "|        Sydney|\n",
      "|     Gladstone|\n",
      "|         Perth|\n",
      "|        Burnie|\n",
      "|       Emerald|\n",
      "|    Ayers Rock|\n",
      "+--------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+--------------------------------------+\n",
      "|Airline                               |\n",
      "+--------------------------------------+\n",
      "|Virgin Australia - ATR/F100 Operations|\n",
      "|Qantas                                |\n",
      "|Virgin Australia                      |\n",
      "|QantasLink                            |\n",
      "|Virgin Australia Regional Airlines    |\n",
      "|Ozjet                                 |\n",
      "|Regional Express                      |\n",
      "|Tigerair Australia                    |\n",
      "|Jetstar                               |\n",
      "|Skywest                               |\n",
      "+--------------------------------------+\n",
      "\n",
      "+-------+------------------+\n",
      "|summary|Departures_Delayed|\n",
      "+-------+------------------+\n",
      "|  count|             61337|\n",
      "|   mean| 17.47837357549277|\n",
      "| stddev| 23.77712957048252|\n",
      "|    min|                 0|\n",
      "|    max|               410|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "readflightDelayDF\n",
    "    .show(5)\n",
    "    \n",
    "readflightDelayDF\n",
    "    .select(\"Departing_Port\")\n",
    "    .distinct()\n",
    "    .show()\n",
    "\n",
    "readflightDelayDF\n",
    "    .select(\"Arriving_Port\")\n",
    "    .distinct()\n",
    "    .show()\n",
    "\n",
    "readflightDelayDF\n",
    "    .select(\"Airline\")\n",
    "    .distinct()\n",
    "    .show(truncate = false)\n",
    "\n",
    "readflightDelayDF\n",
    "    .select(\"Departures_Delayed\")\n",
    "    .describe()\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join The Monthly Fuel Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "flightDelayDF: org.apache.spark.sql.DataFrame = [Month: string, Departing_Port: string ... 9 more fields]\n",
       "res1: Long = 61367\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val flightDelayDF = readflightDelayDF.join(fuelDF, readflightDelayDF(\"Month\") === fuelDF(\"Month\"), \"left\")\n",
    "flightDelayDF.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replicate Aggregated Late Departures with 1's and Not Lates with 0's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flights has 1887845 rows\n",
      "root\n",
      " |-- Departing_Port: string (nullable = true)\n",
      " |-- Arriving_Port: string (nullable = true)\n",
      " |-- Airline: string (nullable = true)\n",
      " |-- label: integer (nullable = false)\n",
      " |-- Year: integer (nullable = true)\n",
      " |-- Month_Num: integer (nullable = true)\n",
      " |-- Fuel_Price: double (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "df2: org.apache.spark.sql.DataFrame = [Month: string, Departing_Port: string ... 9 more fields]\n",
       "df3: org.apache.spark.sql.DataFrame = [Month: string, Departing_Port: string ... 9 more fields]\n",
       "sampleFraction: Double = 0.3\n",
       "flights: org.apache.spark.sql.DataFrame = [Departing_Port: string, Arriving_Port: string ... 5 more fields]\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val df2 = flightDelayDF.withColumn(\"Departures_Delayed\",\n",
    "                            explode(array_repeat(lit(1), $\"Departures_Delayed\")))\n",
    "//df2.show()\n",
    "\n",
    "val df3 = flightDelayDF.withColumn(\"Departures_Delayed\",\n",
    "                            explode(array_repeat(lit(0), $\"Sectors_Flown\"-$\"Departures_Delayed\")))\n",
    "//df3.show()\n",
    "\n",
    "// Take a random sample (without replacement) of the data (to reduce memory requirements)\n",
    "val sampleFraction = 0.3\n",
    "\n",
    "//Concatenate rows df2 and df3 and drop any rows with missing data\n",
    "val flights = (df2.union(df3)\n",
    "                            .drop(\"Sectors_Flown\", \"Month\", \"Change\")\n",
    "                            .withColumnRenamed(\"Departures_Delayed\",\"label\")\n",
    "                            .withColumnRenamed(\"Price\",\"Fuel_Price\")\n",
    "                            .sample(false,sampleFraction).na.drop())\n",
    "\n",
    "println(s\"flights has ${flights.count()} rows\")\n",
    "flights.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determine the fraction of lates in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "proportion of lates (label=1)\n",
      "+-----+-------+\n",
      "|label|  count|\n",
      "+-----+-------+\n",
      "|    1| 320804|\n",
      "|    0|1567041|\n",
      "+-----+-------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "counts: org.apache.spark.sql.DataFrame = [label: int, count: bigint]\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Take a look at the proportion of lates in the dataset\n",
    "val counts = flights.groupBy(\"label\").count()\n",
    "\n",
    "println(\"proportion of lates (label=1)\")\n",
    "counts.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write the Dataframe flights to a file and Read it Back in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Departing_Port: string (nullable = true)\n",
      " |-- Arriving_Port: string (nullable = true)\n",
      " |-- Airline: string (nullable = true)\n",
      " |-- label: integer (nullable = true)\n",
      " |-- Year: integer (nullable = true)\n",
      " |-- Month_Num: integer (nullable = true)\n",
      " |-- Fuel_Price: double (nullable = true)\n",
      "\n",
      "+--------------+-------------+-------+-----+----+---------+----------+\n",
      "|Departing_Port|Arriving_Port|Airline|label|Year|Month_Num|Fuel_Price|\n",
      "+--------------+-------------+-------+-----+----+---------+----------+\n",
      "|      Adelaide|     Brisbane| Qantas|    1|2004|        1|       1.3|\n",
      "|      Adelaide|     Brisbane| Qantas|    1|2004|        1|       1.3|\n",
      "|      Adelaide|     Brisbane| Qantas|    1|2004|        1|       1.3|\n",
      "|      Adelaide|     Brisbane| Qantas|    1|2004|        1|       1.3|\n",
      "|      Adelaide|     Canberra| Qantas|    1|2004|        1|       1.3|\n",
      "+--------------+-------------+-------+-----+----+---------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "flights1: org.apache.spark.sql.DataFrame = [Departing_Port: string, Arriving_Port: string ... 5 more fields]\n"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//flightDelay.parquet\n",
    "\n",
    "//flights.write.parquet(\"flight_data.parquet\")\n",
    "flights.coalesce(1) //Join all partitions into one file\n",
    "      .write\n",
    "      .option(\"header\",\"true\")\n",
    "      .option(\"sep\",\",\")\n",
    "      .mode(\"overwrite\")\n",
    "      .csv(\"flight_data\")\n",
    "\n",
    "val flights1 = spark.read\n",
    "  .option(\"delimiter\",\",\")\n",
    "  .option(\"header\", \"true\")\n",
    "  .option(\"inferSchema\", \"true\")\n",
    "  .csv(\"flight_data\")\n",
    "\n",
    "flights1.printSchema()\n",
    "\n",
    "flights1.show(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
